# src/train.py (‡πÅ‡∏ó‡∏£‡∏Å‡πÑ‡∏ß‡πâ‡∏ö‡∏ô‡∏™‡∏∏‡∏î‡πÄ‡∏•‡∏¢)
import sys
import os

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

import yaml
import json
import argparse
import logging
import torch
import torch.optim as optim
import torch.nn.functional as F
import numpy as np
from tqdm import tqdm
from sklearn.metrics import precision_score

# Import Modules ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡πÅ‡∏¢‡∏Å‡πÑ‡∏ß‡πâ
from src.data.dataset import create_dataloaders
from src.models.architecture import PillModel, FocalLoss

# ============================================================
# ‚öôÔ∏è SYSTEM SETUP
# ============================================================
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger("Trainer")

def set_seed(seed):
    """ ‡∏•‡πá‡∏≠‡∏Ñ‡∏Ñ‡πà‡∏≤‡∏™‡∏∏‡πà‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á (Reproducibility) """
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Mac M1/M2 (MPS)
    if torch.backends.mps.is_available():
        torch.mps.manual_seed(seed)

def load_params(param_path):
    with open(param_path, 'r') as f:
        return yaml.safe_load(f)

# ============================================================
# üîÑ TRAINING & VALIDATION LOOPS
# ============================================================
def train_one_epoch(model, loader, criterion, optimizer, device):
    model.train()
    total_loss, correct, total = 0, 0, 0
    
    # Progress Bar ‡πÅ‡∏ö‡∏ö Clean‡πÜ
    loop = tqdm(loader, desc="üî• Train", leave=False, ncols=100)
    
    for imgs, labels in loop:
        imgs, labels = imgs.to(device), labels.to(device)
        
        optimizer.zero_grad()
        
        # Forward Pass (ArcFace)
        # ‡∏™‡πà‡∏á Labels ‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ ArcFace Margin Product ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
        outputs = model(imgs, labels) 
        
        # Calculate Loss
        loss = criterion(outputs, labels)
        
        # Backward Pass
        loss.backward()
        optimizer.step()
        
        # Metrics Tracking
        total_loss += loss.item() * imgs.size(0)
        preds = torch.argmax(outputs, 1)
        correct += (preds == labels).sum().item()
        total += labels.size(0)
        
        loop.set_postfix(loss=f"{loss.item():.4f}")
        
    return total_loss / total, correct / total

def validate(model, loader, criterion, device):
    model.eval()
    total_loss, correct, total = 0, 0, 0
    all_preds, all_labels = [], []
    
    # ‡∏î‡∏∂‡∏á Center Weights ‡∏Ç‡∏≠‡∏á ArcFace ‡∏°‡∏≤‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Cosine Sim ‡πÅ‡∏ö‡∏ö‡πÄ‡∏û‡∏µ‡∏¢‡∏ß‡πÜ
    # ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏ï‡∏≠‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á (Inference) ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö Cosine Distance
    class_weights = F.normalize(model.head.weight)
    
    with torch.no_grad():
        for imgs, labels in loader:
            imgs, labels = imgs.to(device), labels.to(device)
            
            # 1. Calc Loss (Training Objective) - ‡∏¢‡∏±‡∏á‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ Margin
            outputs_margin = model(imgs, labels)
            loss = criterion(outputs_margin, labels)
            total_loss += loss.item() * imgs.size(0)
            
            # 2. Calc Metric (Real-world Objective) - ‡πÉ‡∏ä‡πâ Clean Cosine Similarity
            embeddings = model(imgs, labels=None) # ‡∏Ç‡∏≠‡πÅ‡∏Ñ‡πà Embeddings
            embeddings_norm = F.normalize(embeddings)
            
            # Dot Product (Cosine Sim) ‡∏Å‡∏±‡∏ö Class Centers
            logits_clean = F.linear(embeddings_norm, class_weights)
            
            preds = torch.argmax(logits_clean, 1)
            correct += (preds == labels).sum().item()
            total += labels.size(0)
            
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
            
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Precision (‡∏Å‡∏±‡∏ô‡πÄ‡∏´‡∏ô‡∏µ‡∏¢‡∏ß‡πÄ‡∏ú‡∏∑‡πà‡∏≠ Class ‡πÑ‡∏°‡πà Balance)
    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)
    
    return total_loss / total, correct / total, precision

# ============================================================
# üöÄ MAIN ORCHESTRATOR
# ============================================================
def main():
    parser = argparse.ArgumentParser(description="Train Pill/Box Classification Model")
    parser.add_argument("--train_dir", required=True, help="Path to training data")
    parser.add_argument("--val_dir", required=True, help="Path to validation data")
    parser.add_argument("--output_dir", required=True, help="Root output directory")
    parser.add_argument("--type", required=True, choices=['pill', 'box'], help="Select config type")
    args = parser.parse_args()

    # 1. Load Config & Setup
    params = load_params("params.yaml")
    
    # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏°‡∏µ Config Type ‡∏ô‡∏µ‡πâ‡∏à‡∏£‡∏¥‡∏á‡πÑ‡∏´‡∏°
    if args.type not in params['train']:
        raise ValueError(f"‚ùå Unknown train type: '{args.type}'. Please check 'train' section in params.yaml")
        
    cfg = params['train'][args.type]  # üî• ‡πÇ‡∏´‡∏•‡∏î Config ‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏° Pill/Box ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ
    
    set_seed(cfg['seed'])
    
    # Auto-Detect Device
    if torch.cuda.is_available():
        device = torch.device("cuda")
    elif torch.backends.mps.is_available():
        device = torch.device("mps")
    else:
        device = torch.device("cpu")
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á Folder ‡∏õ‡∏•‡∏≤‡∏¢‡∏ó‡∏≤‡∏á: output_dir/type (‡πÄ‡∏ä‡πà‡∏ô experiments/v1/pill)
    final_output_dir = os.path.join(args.output_dir, args.type)
    os.makedirs(final_output_dir, exist_ok=True)
    
    logger.info(f"üöÄ Start Training [{args.type.upper()}] on {device}")
    logger.info(f"üìÇ Output Dir: {final_output_dir}")
    logger.info(f"‚öôÔ∏è  Model: {cfg['model_name']} | Epochs: {cfg['epochs']} | BS: {cfg['batch_size']}")

    # 2. Prepare Data
    train_loader, val_loader, classes = create_dataloaders(args.train_dir, args.val_dir, cfg)
    num_classes = len(classes)
    logger.info(f"üìä Found {num_classes} classes")
    
    # Save Class Mapping (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å‡∏ï‡∏≠‡∏ô‡πÄ‡∏≠‡∏≤‡πÑ‡∏õ Deploy!)
    class_map_path = os.path.join(final_output_dir, "class_mapping.json")
    with open(class_map_path, "w") as f:
        json.dump({i: name for i, name in enumerate(classes)}, f, indent=4)

    # 3. Initialize Model
    model = PillModel(
        num_classes=num_classes,
        model_name=cfg['model_name'],
        embed_dim=cfg['embed_dim'],
        dropout=cfg['dropout']
    ).to(device)
    
    criterion = FocalLoss(gamma=cfg['focal']['gamma'], alpha=cfg['focal']['alpha'])
    optimizer = optim.AdamW(model.parameters(), lr=cfg['lr'], weight_decay=cfg['weight_decay'])

    # 4. Training Loop
    best_acc = 0.0
    
    for epoch in range(cfg['epochs']):
        # Train
        t_loss, t_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)
        
        # Validate
        v_loss, v_acc, v_prec = validate(model, val_loader, criterion, device)
        
        # Log Result
        logger.info(
            f"Ep {epoch+1:02d}/{cfg['epochs']} | "
            f"Tr_Loss: {t_loss:.4f} Acc: {t_acc:.4f} | "
            f"Val_Loss: {v_loss:.4f} Acc: {v_acc:.4f} Prec: {v_prec:.4f}"
        )

        # Save Checkpoint (Last Model)
        last_path = os.path.join(final_output_dir, "last_model.pth")
        torch.save({
            'epoch': epoch + 1,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'val_acc': v_acc,
            'config': cfg
        }, last_path)

        # Save Best Model
        if v_acc >= best_acc:
            best_acc = v_acc
            best_path = os.path.join(final_output_dir, "best_model.pth")
            torch.save(model.state_dict(), best_path) # ‡πÄ‡∏ã‡∏ü‡πÅ‡∏Ñ‡πà state_dict ‡πÄ‡∏û‡∏µ‡∏¢‡∏ß‡πÜ ‡∏à‡∏∞‡πÑ‡∏î‡πâ‡πÇ‡∏´‡∏•‡∏î‡∏á‡πà‡∏≤‡∏¢
            logger.info(f"   üåü New Best Saved! (Acc: {best_acc:.4f})")
            
    # 5. Finalize for DVC Metrics
    # DVC ‡∏ä‡∏≠‡∏ö‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå JSON ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥ Plot
    metrics_path = os.path.join(final_output_dir, "metrics.json")
    with open(metrics_path, "w") as f:
        json.dump({"best_val_acc": best_acc, "last_val_acc": v_acc}, f, indent=4)
        
    logger.info("üèÜ Training Completed Successfully!")

if __name__ == "__main__":
    main()